{
  "vocabulary": [
    {
      "word": "Hyperparameter",
      "phonetic": "/ˌhaɪ.pərˈpær.ə.miː.tər/",
      "partOfSpeech": "noun",
      "translation": "超参数",
      "definition": {
        "en": "A parameter whose value is set before the learning process begins, and which determines how a model is structured or behaves.",
        "zh": "在学习过程开始之前设定的参数，这些参数决定了模型的结构或行为。"
      },
      "examples": [
        {
          "en": "The learning rate is an important hyperparameter in neural networks.",
          "zh": "学习率是神经网络中的一个重要超参数。"
        },
        {
          "en": "Hyperparameters need to be tuned to optimize model performance.",
          "zh": "需要调整超参数以优化模型性能。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "Regularization",
      "phonetic": "/ˌreɡ.yə.lərɪˈzeɪʃən/",
      "partOfSpeech": "noun",
      "translation": "正则化",
      "definition": {
        "en": "A technique to prevent overfitting by adding a penalty to the loss function.",
        "zh": "通过在损失函数中加入惩罚项来防止过拟合的技术。"
      },
      "examples": [
        {
          "en": "Lasso and Ridge are types of regularization techniques.",
          "zh": "Lasso和Ridge是正则化技术的类型。"
        },
        {
          "en": "Regularization helps in achieving a model with better generalization.",
          "zh": "正则化有助于实现一个具有更好泛化能力的模型。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "Backpropagation",
      "phonetic": "/ˌbæk.prə.pəˈɡeɪʃən/",
      "partOfSpeech": "noun",
      "translation": "反向传播",
      "definition": {
        "en": "An algorithm for training neural networks by minimizing the error between the predicted and actual outputs.",
        "zh": "一种通过最小化预测输出与实际输出之间的误差来训练神经网络的算法。"
      },
      "examples": [
        {
          "en": "Backpropagation is used to adjust weights in a neural network.",
          "zh": "反向传播用于调整神经网络中的权重。"
        },
        {
          "en": "During backpropagation, the error is propagated backward through the network.",
          "zh": "在反向传播过程中，误差通过网络向后传播。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "Activation Function",
      "phonetic": "/æk.tɪˈveɪ.ʃən ˈfʌŋk.ʃən/",
      "partOfSpeech": "noun",
      "translation": "激活函数",
      "definition": {
        "en": "A function used in neural networks to determine the output of a neuron based on its input.",
        "zh": "在神经网络中用于根据输入确定神经元输出的函数。"
      },
      "examples": [
        {
          "en": "Common activation functions include ReLU, sigmoid, and tanh.",
          "zh": "常见的激活函数包括ReLU、Sigmoid和Tanh。"
        },
        {
          "en": "Choosing the right activation function can significantly impact model performance.",
          "zh": "选择合适的激活函数可以显著影响模型性能。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "Gradient Descent",
      "phonetic": "/ˈɡreɪ.di.ənt dɪˈsent/",
      "partOfSpeech": "noun",
      "translation": "梯度下降",
      "definition": {
        "en": "An optimization algorithm for finding the minimum of a function by iteratively moving in the direction of steepest descent.",
        "zh": "一种通过迭代在最陡下降方向移动来寻找函数最小值的优化算法。"
      },
      "examples": [
        {
          "en": "Gradient descent is used to update the parameters of machine learning models.",
          "zh": "梯度下降用于更新机器学习模型的参数。"
        },
        {
          "en": "Stochastic gradient descent is a variant that samples a subset of the data for each iteration.",
          "zh": "随机梯度下降是每次迭代采样数据子集的变体。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "Overfitting",
      "phonetic": "/ˈoʊ.vɚˌfɪ.tɪŋ/",
      "partOfSpeech": "noun",
      "translation": "过拟合",
      "definition": {
        "en": "A modeling error which occurs when a function is too closely fit to a limited set of data points.",
        "zh": "当一个函数过度贴合一组有限的数据点时发生的建模错误。"
      },
      "examples": [
        {
          "en": "To avoid overfitting, one might use regularization or more training data.",
          "zh": "为了避免过拟合，可以使用正则化或增加训练数据。"
        },
        {
          "en": "Overfitting results in poor generalization to new, unseen data.",
          "zh": "过拟合会导致对新数据的泛化能力较差。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "Epoch",
      "phonetic": "/ˈiː.pɒk/",
      "partOfSpeech": "noun",
      "translation": "轮次",
      "definition": {
        "en": "A complete pass through all the training data in machine learning.",
        "zh": "在机器学习中，对所有训练数据完整遍历一遍。"
      },
      "examples": [
        {
          "en": "The model was trained for 100 epochs.",
          "zh": "模型训练了100轮。"
        },
        {
          "en": "An epoch is one full cycle of applying the learning algorithm to the entire training set.",
          "zh": "一个轮次是对整个训练集应用学习算法的一次完整循环。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "Feature Engineering",
      "phonetic": "/ˈfiː.tʃər ɪn.dʒɪˈnɪərɪŋ/",
      "partOfSpeech": "noun",
      "translation": "特征工程",
      "definition": {
        "en": "The process of using domain knowledge to extract features from raw data that make machine learning algorithms work better.",
        "zh": "使用领域知识从原始数据中提取特征的过程，使得机器学习算法表现得更好。"
      },
      "examples": [
        {
          "en": "Feature engineering can be crucial for the success of a predictive model.",
          "zh": "特征工程对于预测模型的成功至关重要。"
        },
        {
          "en": "Creating new features through transformations or interactions can significantly boost model performance.",
          "zh": "通过转换或交互创建新特征可以显著提高模型性能。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "Convolutional Neural Network",
      "phonetic": "/kɒn.vəˈluːʃən.əl ˈnjʊə.rəl ˈnet.wɜːk/",
      "partOfSpeech": "noun",
      "translation": "卷积神经网络",
      "definition": {
        "en": "A class of deep neural networks, most commonly applied to analyzing visual imagery.",
        "zh": "一种深度神经网络，主要用于分析视觉图像。"
      },
      "examples": [
        {
          "en": "CNNs are particularly good at recognizing patterns in images.",
          "zh": "卷积神经网络特别擅长识别图像中的模式。"
        },
        {
          "en": "A convolutional neural network can automatically and adaptively learn spatial hierarchies of features.",
          "zh": "卷积神经网络可以自动自适应地学习特征的空间层次结构。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "Transfer Learning",
      "phonetic": "/ˈtræns.fɜːr ˈlɜːrnɪŋ/",
      "partOfSpeech": "noun",
      "translation": "迁移学习",
      "definition": {
        "en": "A machine learning method where a model developed for one task is reused as the starting point for a model on a second task.",
        "zh": "一种机器学习方法，其中为一个任务开发的模型被重新用作第二个任务模型的起点。"
      },
      "examples": [
        {
          "en": "Transfer learning can save time and resources by using pre-trained models.",
          "zh": "通过使用预训练模型，迁移学习可以节省时间和资源。"
        },
        {
          "en": "In computer vision, transfer learning from ImageNet is common.",
          "zh": "在计算机视觉中，从ImageNet进行迁移学习很常见。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "autoencoder",
      "phonetic": "/ˈɔːtəʊˌɛn.kəʊdə/",
      "partOfSpeech": "noun",
      "translation": "自编码器",
      "definition": {
        "en": "A type of neural network that learns how to efficiently compress and encode data, then decode to reproduce the original input as closely as possible.",
        "zh": "一种神经网络，通过学习有效压缩和编码数据，然后解码以尽可能准确地重现原始输入。"
      },
      "examples": [
        {
          "en": "Autoencoders are often used for dimensionality reduction in data preprocessing.",
          "zh": "自编码器常用于数据预处理中的降维。"
        },
        {
          "en": "They can be applied to anomaly detection by training on normal data.",
          "zh": "它们可以通过在正常数据上进行训练来应用于异常检测。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "ensemble learning",
      "phonetic": "/ɒnˈsɛmbəl ˈlɜːnɪŋ/",
      "partOfSpeech": "noun",
      "translation": "集成学习",
      "definition": {
        "en": "A technique that combines the predictions from multiple machine learning models to improve the overall performance.",
        "zh": "一种技术，将多个机器学习模型的预测结果结合起来以提高整体表现。"
      },
      "examples": [
        {
          "en": "Ensemble learning methods like Random Forests often provide better accuracy than single decision trees.",
          "zh": "像随机森林这样的集成学习方法通常比单一决策树提供更好的准确性。"
        },
        {
          "en": "Boosting is another popular ensemble method used to reduce bias and variance in model predictions.",
          "zh": "提升是另一种流行的集成方法，用于减少模型预测中的偏差和方差。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "k-nearest neighbors",
      "phonetic": "/ˌkeɪ ˈnɪərɪst ˈneɪbəz/",
      "partOfSpeech": "noun",
      "translation": "k近邻",
      "definition": {
        "en": "A non-parametric method used for classification and regression which uses the k closest training examples in the feature space to predict the class or value of an unknown point.",
        "zh": "一种用于分类和回归的非参数方法，使用特征空间中k个最近的训练样本来预测未知点的类别或值。"
      },
      "examples": [
        {
          "en": "In k-nearest neighbors, the value of k can significantly affect the performance of the model.",
          "zh": "在k近邻中，k的值可以显著影响模型的性能。"
        },
        {
          "en": "This algorithm is often used in recommender systems to suggest items similar to those a user has liked.",
          "zh": "该算法常用于推荐系统中，建议用户可能喜欢的类似项目。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "latent variable",
      "phonetic": "/ˈleɪtənt ˈværɪəb(ə)l/",
      "partOfSpeech": "noun",
      "translation": "潜在变量",
      "definition": {
        "en": "A variable that is not directly observed but rather inferred (through a mathematical model) from other variables that are observed.",
        "zh": "一种不是直接观察到，而是通过数学模型从其他观察到的变量中推断出的变量。"
      },
      "examples": [
        {
          "en": "In probabilistic models, latent variables help explain the relationships between observed data.",
          "zh": "在概率模型中，潜在变量有助于解释观察数据之间的关系。"
        },
        {
          "en": "Latent Dirichlet Allocation uses latent variables to discover topics in text corpora.",
          "zh": "潜在狄利克雷分配使用潜在变量在文本语料库中发现主题。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "support vector machine",
      "phonetic": "/səˈpɔːt ˈvɛktə məˈʃiːn/",
      "partOfSpeech": "noun",
      "translation": "支持向量机",
      "definition": {
        "en": "A supervised learning model that analyzes data used for classification and regression analysis, finding the best boundary that separates classes.",
        "zh": "一种监督学习模型，用于分类和回归分析，寻找分离类别的最佳边界。"
      },
      "examples": [
        {
          "en": "Support Vector Machines are particularly well suited for classification of complex but small or medium-sized datasets.",
          "zh": "支持向量机特别适用于复杂但小型或中型数据集的分类。"
        },
        {
          "en": "They work by constructing hyperplanes in a multidimensional space that separates cases of different class labels.",
          "zh": "它们通过在多维空间中构建超平面来分离不同类别标签的案例。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "stochastic gradient descent",
      "phonetic": "/stəˈkæstɪk ˈɡreɪdiənt dɪˈsɛnt/",
      "partOfSpeech": "noun",
      "translation": "随机梯度下降",
      "definition": {
        "en": "An iterative method for optimizing an objective function with suitable smoothness properties, where only a random subset of the data is used at each iteration.",
        "zh": "一种迭代方法，用于优化具有适当平滑属性的目标函数，每次迭代仅使用数据的一个随机子集。"
      },
      "examples": [
        {
          "en": "Stochastic gradient descent can be faster than batch gradient descent when dealing with large datasets.",
          "zh": "处理大数据集时，随机梯度下降比批量梯度下降更快。"
        },
        {
          "en": "It's widely used in online machine learning where data is continuously streaming in.",
          "zh": "它广泛应用于在线机器学习中，数据持续流入。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "decision boundary",
      "phonetic": "/dɪˈsɪʒən ˈbaʊndəri/",
      "partOfSpeech": "noun",
      "translation": "决策边界",
      "definition": {
        "en": "The boundary that separates different classes in a classification problem, often visualized in feature space.",
        "zh": "在分类问题中分离不同类别的边界，通常在特征空间中可视化。"
      },
      "examples": [
        {
          "en": "The decision boundary in a logistic regression model is a hyperplane.",
          "zh": "逻辑回归模型中的决策边界是一个超平面。"
        },
        {
          "en": "A complex decision boundary might indicate overfitting in a model.",
          "zh": "复杂的决策边界可能表明模型过拟合。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "principal component analysis",
      "phonetic": "/ˈprɪnsɪpəl kəmˈpəʊnənt əˈnæləsɪs/",
      "partOfSpeech": "noun",
      "translation": "主成分分析",
      "definition": {
        "en": "A statistical procedure that uses orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables.",
        "zh": "一种统计程序，使用正交变换将一组可能相关变量的观测值转换为一组线性不相关的变量值。"
      },
      "examples": [
        {
          "en": "Principal Component Analysis is often used to reduce the dimensionality of datasets.",
          "zh": "主成分分析常用于降低数据集的维度。"
        },
        {
          "en": "It helps in visualizing data by reducing it to its principal components.",
          "zh": "通过将其减少到主成分，它有助于可视化数据。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "ensemble method",
      "phonetic": "/ɒnˈsɛmbəl ˈmɛθəd/",
      "partOfSpeech": "noun",
      "translation": "集成方法",
      "definition": {
        "en": "Techniques that create multiple models and then combine their predictions to improve robustness over a single model.",
        "zh": "创建多个模型并结合其预测以提高单一模型稳健性的技术。"
      },
      "examples": [
        {
          "en": "Bagging and boosting are two common ensemble methods.",
          "zh": "装袋和提升是两种常见的集成方法。"
        },
        {
          "en": "Ensemble methods can significantly reduce both bias and variance in predictions.",
          "zh": "集成方法可以显著降低预测中的偏差和方差。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "feature selection",
      "phonetic": "/ˈfiːtʃə sɪˈlɛkʃən/",
      "partOfSpeech": "noun",
      "translation": "特征选择",
      "definition": {
        "en": "The process of selecting a subset of relevant features for use in model construction to improve performance and reduce dimensionality.",
        "zh": "选择相关特征子集用于模型构建以提高性能和减少维度的过程。"
      },
      "examples": [
        {
          "en": "Feature selection can help in dealing with the curse of dimensionality.",
          "zh": "特征选择可以帮助处理维度灾难。"
        },
        {
          "en": "Methods like Lasso or Ridge regression can perform feature selection automatically.",
          "zh": "Lasso或Ridge回归等方法可以自动执行特征选择。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "kernel trick",
      "phonetic": "/ˈkɜːnəl trɪk/",
      "partOfSpeech": "noun",
      "translation": "核技巧",
      "definition": {
        "en": "A method used in Support Vector Machines (SVMs) to operate in a high-dimensional feature space without explicitly computing the coordinates of the data in that space.",
        "zh": "支持向量机（SVM）中用于在高维特征空间操作而不显式计算该空间中数据坐标的方法。"
      },
      "examples": [
        {
          "en": "The kernel trick allows SVMs to handle non-linear classification problems.",
          "zh": "核技巧使得SVM能够处理非线性分类问题。"
        },
        {
          "en": "By using the kernel trick, we can transform the data into a higher dimension.",
          "zh": "通过使用核技巧，我们可以将数据转换到更高维度。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "reinforcement learning",
      "phonetic": "/ˌriː.ɪnˈfɔːs.mənt ˈlɜːnɪŋ/",
      "partOfSpeech": "noun",
      "translation": "强化学习",
      "definition": {
        "en": "An area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.",
        "zh": "机器学习的一个领域，关注软件代理应该如何在环境中采取行动以最大化累积奖励的概念。"
      },
      "examples": [
        {
          "en": "Reinforcement learning has been successfully applied to train agents in complex game environments.",
          "zh": "强化学习已成功应用于在复杂游戏环境中训练代理。"
        },
        {
          "en": "In reinforcement learning, the agent learns from trial and error.",
          "zh": "在强化学习中，代理通过试错来学习。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "feature extraction",
      "phonetic": "/ˈfiːtʃər ɪkˈstrækʃən/",
      "partOfSpeech": "noun",
      "translation": "特征提取",
      "definition": {
        "en": "The process of reducing the number of resources required to describe a large set of data by transforming the data into a reduced set of features.",
        "zh": "通过将数据转换为一组减少的特征来减少描述大量数据所需资源的过程。"
      },
      "examples": [
        {
          "en": "Feature extraction is crucial for dimensionality reduction.",
          "zh": "特征提取对降维至关重要。"
        },
        {
          "en": "In image processing, feature extraction helps in identifying objects or patterns.",
          "zh": "在图像处理中，特征提取有助于识别对象或模式。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "loss function",
      "phonetic": "/ˈlɒs ˈfʌŋkʃən/",
      "partOfSpeech": "noun",
      "translation": "损失函数",
      "definition": {
        "en": "A function that maps an event or values of one or more variables onto a real number intuitively representing some 'cost' associated with the event.",
        "zh": "将事件或一个或多个变量的值映射到实数上的函数，直观地表示与事件相关联的某种“成本”。"
      },
      "examples": [
        {
          "en": "The choice of loss function can significantly affect the performance of a machine learning model.",
          "zh": "损失函数的选择会显著影响机器学习模型的性能。"
        },
        {
          "en": "Mean squared error is a commonly used loss function in regression problems.",
          "zh": "均方误差是回归问题中常用的损失函数。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "dimensionality reduction",
      "phonetic": "/ˌdɪmɛnʃəˈnælɪti rɪˈdʌkʃən/",
      "partOfSpeech": "noun",
      "translation": "降维",
      "definition": {
        "en": "The process of reducing the number of random variables under consideration by obtaining a set of principal variables.",
        "zh": "通过获取一组主变量来减少考虑的随机变量数量的过程。"
      },
      "examples": [
        {
          "en": "Dimensionality reduction techniques like PCA are used to simplify data without losing much information.",
          "zh": "像PCA这样的降维技术用于在不损失太多信息的情况下简化数据。"
        },
        {
          "en": "Applying dimensionality reduction can help visualize high-dimensional data in lower dimensions.",
          "zh": "应用降维可以帮助在低维度上可视化高维数据。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "neural network pruning",
      "phonetic": "/ˈnjʊərəl ˈnetwɜːrk ˈpruːnɪŋ/",
      "partOfSpeech": "noun",
      "translation": "神经网络修剪",
      "definition": {
        "en": "The process of removing redundant or less important connections or neurons from a neural network to reduce its size and improve efficiency.",
        "zh": "从神经网络中移除冗余或不重要的连接或神经元的过程，以减少其规模并提高效率。"
      },
      "examples": [
        {
          "en": "Neural network pruning can help reduce overfitting and computational complexity.",
          "zh": "神经网络修剪可以帮助减少过拟合和计算复杂性。"
        },
        {
          "en": "After training, pruning the network can make it more deployable on edge devices.",
          "zh": "在训练之后，修剪网络可以使其更适合在边缘设备上部署。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "bias-variance tradeoff",
      "phonetic": "/ˈbaɪəs ˈveərɪəns ˈtreɪdɒf/",
      "partOfSpeech": "noun",
      "translation": "偏差-方差权衡",
      "definition": {
        "en": "The problem of simultaneously minimizing two sources of error that prevent supervised learning algorithms from generalizing beyond their training set: the bias and variance.",
        "zh": "同时最小化两个阻止监督学习算法在训练集之外泛化的误差来源的问题：偏差和方差。"
      },
      "examples": [
        {
          "en": "Understanding the bias-variance tradeoff is crucial for designing effective machine learning models.",
          "zh": "理解偏差-方差权衡对于设计有效的机器学习模型至关重要。"
        },
        {
          "en": "Increasing model complexity can reduce bias but might increase variance.",
          "zh": "增加模型复杂性可以减少偏差，但可能会增加方差。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "convolutional layer",
      "phonetic": "/kənˌvɒl.jʊˈteɪ.ʃən.əl ˈleɪ.ər/",
      "partOfSpeech": "noun",
      "translation": "卷积层",
      "definition": {
        "en": "A layer in a convolutional neural network that applies a convolution operation to the input, passing the result to the next layer.",
        "zh": "卷积神经网络中的一层，对输入应用卷积操作，并将结果传递到下一层。"
      },
      "examples": [
        {
          "en": "The convolutional layer reduces the dimensionality of images.",
          "zh": "卷积层减少图像的维度。"
        },
        {
          "en": "Each convolutional layer extracts different features from the input data.",
          "zh": "每个卷积层从输入数据中提取不同的特征。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "dropout",
      "phonetic": "/ˈdrɒp.aʊt/",
      "partOfSpeech": "noun",
      "translation": "丢弃法",
      "definition": {
        "en": "A regularization technique where randomly selected neurons are ignored during training to prevent overfitting.",
        "zh": "一种正则化技术，在训练期间随机选择并忽略神经元，以防止过拟合。"
      },
      "examples": [
        {
          "en": "Dropout is used to improve the generalization of neural networks.",
          "zh": "丢弃法用于提高神经网络的泛化能力。"
        },
        {
          "en": "Applying dropout can significantly reduce overfitting in complex models.",
          "zh": "应用丢弃法可以在复杂模型中显著减少过拟合。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "GAN",
      "phonetic": "/ɡæn/",
      "partOfSpeech": "noun",
      "translation": "生成对抗网络",
      "definition": {
        "en": "A class of machine learning systems where two neural networks contest with each other in a game.",
        "zh": "一种机器学习系统，其中两个神经网络在游戏中相互竞争。"
      },
      "examples": [
        {
          "en": "GANs are used to generate realistic images.",
          "zh": "生成对抗网络用于生成逼真的图像。"
        },
        {
          "en": "In GANs, one network generates candidates and the other evaluates them.",
          "zh": "在生成对抗网络中，一个网络生成候选者，另一个网络对其进行评估。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "decision tree",
      "phonetic": "/dɪˈsɪʒən ˈtriː/",
      "partOfSpeech": "noun",
      "translation": "决策树",
      "definition": {
        "en": "A flowchart-like structure in which each internal node represents a 'test' on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label.",
        "zh": "一种类似流程图的结构，其中每个内部节点代表对一个属性的“测试”，每个分支代表测试的结果，每个叶节点代表一个类别标签。"
      },
      "examples": [
        {
          "en": "Decision trees are often used in decision-making processes.",
          "zh": "决策树常用于决策过程。"
        },
        {
          "en": "Random forests are an ensemble of decision trees.",
          "zh": "随机森林是决策树的集成。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "k-means clustering",
      "phonetic": "/ˌkeɪ ˈmiːnz ˈklʌstərɪŋ/",
      "partOfSpeech": "noun",
      "translation": "K均值聚类",
      "definition": {
        "en": "An unsupervised algorithm that partitions n observations into k clusters where each observation belongs to the cluster with the nearest mean.",
        "zh": "一种无监督算法，将n个观察值划分为k个簇，每个观察值属于最近平均值的簇。"
      },
      "examples": [
        {
          "en": "K-means clustering can group similar data points together.",
          "zh": "K均值聚类可以将相似的数据点聚集在一起。"
        },
        {
          "en": "The algorithm iteratively assigns points to clusters to minimize within-cluster variance.",
          "zh": "该算法通过迭代将点分配到簇中以最小化簇内方差。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "Bayesian optimization",
      "phonetic": "/beɪˈziːən ˌɒptɪmaɪˈzeɪʃən/",
      "partOfSpeech": "noun",
      "translation": "贝叶斯优化",
      "definition": {
        "en": "A sequential design strategy for global optimization of black-box functions that does not assume any functional forms.",
        "zh": "一种用于全局优化黑盒函数的顺序设计策略，不假设任何功能形式。"
      },
      "examples": [
        {
          "en": "Bayesian optimization is effective for tuning hyperparameters.",
          "zh": "贝叶斯优化在调节超参数时非常有效。"
        },
        {
          "en": "It reduces the number of experiments needed to find a good set of parameters.",
          "zh": "它减少了找到一组好参数所需的实验次数。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "tensor",
      "phonetic": "/ˈtɛnsər/",
      "partOfSpeech": "noun",
      "translation": "张量",
      "definition": {
        "en": "A generalization of vectors and matrices to potentially higher dimensions, used in deep learning to represent data and operations.",
        "zh": "向量和矩阵的推广，可能用于更高维度，在深度学习中用来表示数据和操作。"
      },
      "examples": [
        {
          "en": "In TensorFlow, operations are performed on tensors.",
          "zh": "在TensorFlow中，操作是在张量上进行的。"
        },
        {
          "en": "A tensor of rank 3 can represent a color image with its three color channels.",
          "zh": "秩为3的张量可以表示具有三个颜色通道的彩色图像。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "batch normalization",
      "phonetic": "/bætʃ ˌnɔːməlɪˈzeɪʃən/",
      "partOfSpeech": "noun",
      "translation": "批量归一化",
      "definition": {
        "en": "A method used to improve the training of deep neural networks by normalizing the inputs of each layer to have zero mean and unit variance.",
        "zh": "一种通过归一化每一层输入以具有零均值和单位方差来改善深度神经网络训练的方法。"
      },
      "examples": [
        {
          "en": "Batch normalization helps in reducing internal covariate shift.",
          "zh": "批量归一化有助于减少内部协变量偏移。"
        },
        {
          "en": "Using batch normalization often allows higher learning rates and acts as a regularizer.",
          "zh": "使用批量归一化通常允许更高的学习率，并且起到正则化的作用。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "L1 regularization",
      "phonetic": "/ˌɛl wʌn ˌrɛɡjələrɪˈzeɪʃən/",
      "partOfSpeech": "noun",
      "translation": "L1正则化",
      "definition": {
        "en": "A regularization technique where the cost added to the loss function is proportional to the absolute value of the weights.",
        "zh": "一种正则化技术，其添加到损失函数中的成本与权重的绝对值成比例。"
      },
      "examples": [
        {
          "en": "L1 regularization promotes sparsity in model parameters.",
          "zh": "L1正则化促进模型参数的稀疏性。"
        },
        {
          "en": "Using L1 regularization can help in feature selection by setting some weights to zero.",
          "zh": "使用L1正则化可以通过将一些权重设为零来帮助特征选择。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "hyperparameter tuning",
      "phonetic": "/ˌhaɪ.pɜːrˌpærəˈmiː.tər ˈtjuː.nɪŋ/",
      "partOfSpeech": "noun",
      "translation": "超参数调优",
      "definition": {
        "en": "The process of optimizing the parameters of a machine learning model that are not learned during training but set beforehand.",
        "zh": "优化那些在训练过程中未学习而是预先设置的机器学习模型参数的过程。"
      },
      "examples": [
        {
          "en": "Grid search is a common method for hyperparameter tuning.",
          "zh": "网格搜索是超参数调优的常用方法。"
        },
        {
          "en": "Hyperparameter tuning can significantly impact model performance.",
          "zh": "超参数调优可以显著影响模型性能。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "hyperplane",
      "phonetic": "/ˈhaɪpərpleɪn/",
      "partOfSpeech": "noun",
      "translation": "超平面",
      "definition": {
        "en": "A subspace of one dimension less than its ambient space, often used in classification algorithms like SVM.",
        "zh": "比其环境空间维度少一维的子空间，常用于分类算法如支持向量机（SVM）。"
      },
      "examples": [
        {
          "en": "A hyperplane separates the data into different classes in SVM.",
          "zh": "在SVM中，超平面将数据分成不同的类别。"
        },
        {
          "en": "The distance from points to the hyperplane determines the margin.",
          "zh": "点到超平面的距离决定了边界。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "feedforward neural network",
      "phonetic": "/ˈfiːdˌfɔːwərd ˈnɜːrəl ˈnɛtwɜːrk/",
      "partOfSpeech": "noun",
      "translation": "前馈神经网络",
      "definition": {
        "en": "A type of artificial neural network where connections between the nodes do not form a cycle.",
        "zh": "一种人工神经网络，其节点之间的连接不形成循环。"
      },
      "examples": [
        {
          "en": "A feedforward neural network is often used for pattern recognition.",
          "zh": "前馈神经网络常用于模式识别。"
        },
        {
          "en": "In a feedforward network, information moves only forward.",
          "zh": "在前馈网络中，信息只向前移动。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "data augmentation",
      "phonetic": "/ˈdeɪtə ˌɔːɡmənˈteɪʃən/",
      "partOfSpeech": "noun",
      "translation": "数据增强",
      "definition": {
        "en": "Techniques used to increase the amount of data by adding slightly modified copies or synthesized data from existing data.",
        "zh": "通过添加略有修改的副本或从现有数据中合成数据来增加数据量的方法。"
      },
      "examples": [
        {
          "en": "Data augmentation helps in improving model performance when training data is limited.",
          "zh": "当训练数据有限时，数据增强有助于提高模型性能。"
        },
        {
          "en": "Common techniques include rotation, flipping, and zooming of images.",
          "zh": "常见技术包括图像的旋转、翻转和缩放。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "Bayesian network",
      "phonetic": "/beɪˈzɪən ˈnɛtwɜːk/",
      "partOfSpeech": "noun",
      "translation": "贝叶斯网络",
      "definition": {
        "en": "A probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph.",
        "zh": "一种概率图模型，通过有向无环图表示一组变量及其条件依赖关系。"
      },
      "examples": [
        {
          "en": "Bayesian networks are used in medical diagnosis for uncertainty modeling.",
          "zh": "贝叶斯网络在医学诊断中用于不确定性建模。"
        },
        {
          "en": "We constructed a Bayesian network to predict equipment failure rates.",
          "zh": "我们构建了一个贝叶斯网络来预测设备故障率。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "genetic algorithm",
      "phonetic": "/dʒɪˈnɛtɪk ˈælɡərɪðəm/",
      "partOfSpeech": "noun",
      "translation": "遗传算法",
      "definition": {
        "en": "A search heuristic that mimics the process of natural selection to generate solutions to optimization and search problems.",
        "zh": "一种模拟自然选择过程的搜索启发式方法，用于生成优化和搜索问题的解决方案。"
      },
      "examples": [
        {
          "en": "Genetic algorithms are used in optimization tasks where traditional methods fail.",
          "zh": "遗传算法在传统方法失败的优化任务中被使用。"
        },
        {
          "en": "The genetic algorithm evolved the population over generations to find the best solution.",
          "zh": "遗传算法通过几代进化来寻找最佳解决方案。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "anomaly detection",
      "phonetic": "/əˈnɒməli dɪˈtɛkʃən/",
      "partOfSpeech": "noun",
      "translation": "异常检测",
      "definition": {
        "en": "The identification of items, events, or observations which do not conform to an expected pattern or other items in a dataset.",
        "zh": "识别不符合数据集中的预期模式或其他项目的项目、事件或观测值。"
      },
      "examples": [
        {
          "en": "Anomaly detection algorithms are critical for fraud detection in banking.",
          "zh": "异常检测算法在银行业的欺诈检测中至关重要。"
        },
        {
          "en": "In network security, anomaly detection helps in identifying unusual traffic patterns.",
          "zh": "在网络安全中，异常检测有助于识别不寻常的流量模式。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "gradient boosting",
      "phonetic": "/ˈɡreɪdiənt ˈbuːstɪŋ/",
      "partOfSpeech": "noun",
      "translation": "梯度提升",
      "definition": {
        "en": "A machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models.",
        "zh": "一种用于回归和分类问题的机器学习技术，生成由弱预测模型组成的集合形式的预测模型。"
      },
      "examples": [
        {
          "en": "Gradient boosting is often used in competitions due to its high performance.",
          "zh": "由于其高性能，梯度提升常用于比赛中。"
        },
        {
          "en": "XGBoost is a popular implementation of gradient boosting.",
          "zh": "XGBoost是梯度提升的流行实现。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "word embedding",
      "phonetic": "/wɜːrd ɪmˈbɛdɪŋ/",
      "partOfSpeech": "noun",
      "translation": "词嵌入",
      "definition": {
        "en": "A representation of words for text analysis, typically through a dense vector where words with similar meanings have similar vectors.",
        "zh": "用于文本分析的词表示，通常通过一个密集向量，其中意思相似的词具有相似的向量。"
      },
      "examples": [
        {
          "en": "Word embeddings like Word2Vec or GloVe help in capturing semantic relationships between words.",
          "zh": "像Word2Vec或GloVe这样的词嵌入有助于捕捉词之间的语义关系。"
        },
        {
          "en": "By using word embeddings, machine learning models can better understand context in natural language processing tasks.",
          "zh": "通过使用词嵌入，机器学习模型能够更好地理解自然语言处理任务中的上下文。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "perceptron",
      "phonetic": "/pərˈsɛptrən/",
      "partOfSpeech": "noun",
      "translation": "感知机",
      "definition": {
        "en": "An algorithm for binary classifiers which uses a linear combination of the input features to make predictions.",
        "zh": "用于二分类器的算法，它使用输入特征的线性组合进行预测。"
      },
      "examples": [
        {
          "en": "The perceptron can learn and correctly classify data if the data is linearly separable.",
          "zh": "如果数据是线性可分的，感知机可以学习并正确分类数据。"
        },
        {
          "en": "A single-layer perceptron can only solve linearly separable problems.",
          "zh": "单层感知机只能解决线性可分的问题。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "generative adversarial network",
      "phonetic": "/ˈdʒɛnərətɪv ˌæd.vərˈsɛərɪəl ˈnɛtwɜːrk/",
      "partOfSpeech": "noun",
      "translation": "生成对抗网络",
      "definition": {
        "en": "A class of machine learning frameworks designed by two neural networks contesting with each other in a zero-sum game.",
        "zh": "一类由两个神经网络在零和博弈中相互竞争设计的机器学习框架。"
      },
      "examples": [
        {
          "en": "GANs can generate new images that look authentic to human observers.",
          "zh": "生成对抗网络可以生成看起来对人类观察者真实的新图像。"
        },
        {
          "en": "They are used for tasks like image synthesis, style transfer, and more.",
          "zh": "它们被用于图像合成、风格迁移等任务。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "clustering",
      "phonetic": "/ˈklʌstərɪŋ/",
      "partOfSpeech": "noun",
      "translation": "聚类",
      "definition": {
        "en": "The task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups.",
        "zh": "将一组对象进行分组，使得同一组内的对象彼此之间比与其他组的对象更相似。"
      },
      "examples": [
        {
          "en": "K-means clustering is widely used for market segmentation.",
          "zh": "K-means聚类广泛用于市场细分。"
        },
        {
          "en": "Clustering was applied to find natural groupings in the dataset.",
          "zh": "聚类被应用于在数据集中找到自然分组。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "normalization",
      "phonetic": "/ˌnɔː.məl.aɪˈzeɪ.ʃən/",
      "partOfSpeech": "noun",
      "translation": "归一化",
      "definition": {
        "en": "A data preprocessing technique to change the values of numeric columns in the data to a common scale, without distorting differences in the ranges of values.",
        "zh": "一种数据预处理技术，用于将数据中数值列的值转换到一个共同的尺度，而不失真值域的差异。"
      },
      "examples": [
        {
          "en": "Normalization can speed up learning in neural networks.",
          "zh": "归一化可以加速神经网络的学习。"
        },
        {
          "en": "We normalized the dataset before feeding it into the model.",
          "zh": "我们在将数据集输入模型之前进行了归一化处理。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "cross-validation",
      "phonetic": "/ˈkrɒs vəˌlɪdˈeɪʃən/",
      "partOfSpeech": "noun",
      "translation": "交叉验证",
      "definition": {
        "en": "A technique for assessing how the results of a statistical analysis will generalize to an independent dataset.",
        "zh": "一种评估统计分析结果在独立数据集上泛化能力的技术。"
      },
      "examples": [
        {
          "en": "Cross-validation helps in estimating the model's performance more accurately.",
          "zh": "交叉验证有助于更准确地估计模型性能。"
        },
        {
          "en": "K-fold cross-validation is a common approach where the dataset is split into k subsets.",
          "zh": "K折交叉验证是一种常见的方法，其中数据集被分成k个子集。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "feature scaling",
      "phonetic": "/ˈfiːtʃər ˈskeɪlɪŋ/",
      "partOfSpeech": "noun",
      "translation": "特征缩放",
      "definition": {
        "en": "The process of standardizing the range of independent variables or features of data.",
        "zh": "标准化数据的独立变量或特征范围的过程。"
      },
      "examples": [
        {
          "en": "Feature scaling is often necessary for algorithms like SVM or k-means clustering.",
          "zh": "特征缩放在像SVM或k-means聚类这样的算法中通常是必要的。"
        },
        {
          "en": "Without feature scaling, some algorithms might be biased towards features with larger ranges.",
          "zh": "没有特征缩放，一些算法可能会偏向于具有更大范围的特征。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "manifold learning",
      "phonetic": "/ˈmænɪfəʊld ˈlɜːnɪŋ/",
      "partOfSpeech": "noun",
      "translation": "流形学习",
      "definition": {
        "en": "A type of non-linear dimensionality reduction method that seeks to find lower-dimensional representations of data.",
        "zh": "一种非线性降维方法，旨在寻找数据的低维表示。"
      },
      "examples": [
        {
          "en": "Manifold learning can reveal the underlying structure of complex data sets.",
          "zh": "流形学习可以揭示复杂数据集的底层结构。"
        },
        {
          "en": "Algorithms like Isomap and t-SNE are examples of manifold learning techniques.",
          "zh": "Isomap 和 t-SNE 是流形学习技术的例子。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "sequence modeling",
      "phonetic": "/ˈsiːkwəns ˈmɒdəlɪŋ/",
      "partOfSpeech": "noun",
      "translation": "序列建模",
      "definition": {
        "en": "A type of modeling where the order of data points is considered crucial, often used in natural language processing and time series analysis.",
        "zh": "一种建模类型，其中数据点的顺序被认为是至关重要的，常用于自然语言处理和时间序列分析。"
      },
      "examples": [
        {
          "en": "Recurrent Neural Networks are commonly used for sequence modeling.",
          "zh": "循环神经网络通常用于序列建模。"
        },
        {
          "en": "Sequence modeling can predict the next word in a sentence or the future values in a time series.",
          "zh": "序列建模可以预测句子中的下一个单词或时间序列中的未来值。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "latent space",
      "phonetic": "/ˈleɪ.tənt speɪs/",
      "partOfSpeech": "noun",
      "translation": "潜在空间",
      "definition": {
        "en": "A reduced-dimensionality space that represents the hidden structure or relationships within the data.",
        "zh": "一个降维空间，代表数据中的隐藏结构或关系。"
      },
      "examples": [
        {
          "en": "In autoencoders, the latent space often represents the most compact form of the input data.",
          "zh": "在自编码器中，潜在空间通常代表输入数据的最紧凑形式。"
        },
        {
          "en": "Generative models like VAEs use the latent space to generate new data samples.",
          "zh": "像变分自编码器（VAEs）这样的生成模型使用潜在空间来生成新的数据样本。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "tuning",
      "phonetic": "/ˈtuːnɪŋ/",
      "partOfSpeech": "noun",
      "translation": "调参",
      "definition": {
        "en": "The process of optimizing the parameters of a model to improve its performance on a given task.",
        "zh": "优化模型参数以提高其在给定任务上的性能的过程。"
      },
      "examples": [
        {
          "en": "Hyperparameter tuning can be done manually or through automated techniques like grid search.",
          "zh": "超参数调参可以通过手动或自动化技术如网格搜索来完成。"
        },
        {
          "en": "Model tuning is crucial for achieving the best possible performance.",
          "zh": "模型调参对于实现最佳性能至关重要。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "pruning",
      "phonetic": "/ˈpruːnɪŋ/",
      "partOfSpeech": "noun",
      "translation": "修剪",
      "definition": {
        "en": "The process of reducing the size of decision trees by removing sections of the tree that provide little power to classify instances.",
        "zh": "通过移除对分类实例帮助甚微的树部分来减少决策树大小的过程。"
      },
      "examples": [
        {
          "en": "Pruning helps in preventing overfitting in decision tree models.",
          "zh": "修剪有助于防止决策树模型中的过拟合。"
        },
        {
          "en": "Post-pruning was applied to our decision tree to improve its performance on unseen data.",
          "zh": "我们对决策树进行了后修剪，以提高其在未见数据上的表现。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "kernel density estimation",
      "phonetic": "/ˈkɜː.nəl ˈdɛnsɪti ˌɛstɪˈmeɪʃən/",
      "partOfSpeech": "noun",
      "translation": "核密度估计",
      "definition": {
        "en": "A non-parametric way to estimate the probability density function of a random variable.",
        "zh": "一种非参数化的方法，用于估计随机变量的概率密度函数。"
      },
      "examples": [
        {
          "en": "Kernel Density Estimation is often used in data visualization.",
          "zh": "核密度估计常用于数据可视化。"
        },
        {
          "en": "The choice of kernel function affects the smoothness of the density estimate.",
          "zh": "核函数的选择影响密度估计的平滑度。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "recurrent neural network",
      "phonetic": "/rɪˌkʌrənt ˈnjʊərəl ˈnɛtwɜːrk/",
      "partOfSpeech": "noun",
      "translation": "递归神经网络",
      "definition": {
        "en": "A class of neural networks where connections between nodes form a directed graph along a sequence, allowing it to use internal memory to process sequences of inputs.",
        "zh": "一类神经网络，其节点之间的连接形成一个沿序列的有向图，允许它使用内部记忆来处理输入序列。"
      },
      "examples": [
        {
          "en": "Recurrent neural networks are effective for time series prediction.",
          "zh": "递归神经网络在时间序列预测方面很有效。"
        },
        {
          "en": "LSTMs are a type of recurrent neural network designed to avoid the vanishing gradient problem.",
          "zh": "LSTM是设计用来避免梯度消失问题的递归神经网络类型。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "attention mechanism",
      "phonetic": "/əˈtɛnʃən ˈmɛkəˌnɪzəm/",
      "partOfSpeech": "noun",
      "translation": "注意力机制",
      "definition": {
        "en": "A component in neural networks that allows the model to focus on certain parts of the input data while processing it.",
        "zh": "神经网络中的一个组件，使模型在处理输入数据时能够集中注意力在某些部分。"
      },
      "examples": [
        {
          "en": "The attention mechanism in transformers helps in understanding the context in natural language processing tasks.",
          "zh": "变换器中的注意力机制有助于在自然语言处理任务中理解上下文。"
        },
        {
          "en": "In machine translation, attention helps in aligning words or phrases between source and target languages.",
          "zh": "在机器翻译中，注意力有助于在源语言和目标语言之间对齐单词或短语。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "federated learning",
      "phonetic": "/ˈfɛdəˌreɪtɪd ˈlɜrnɪŋ/",
      "partOfSpeech": "noun",
      "translation": "联邦学习",
      "definition": {
        "en": "A machine learning approach where multiple parties train a model collaboratively without sharing their data directly.",
        "zh": "一种机器学习方法，多个参与方协作训练一个模型而无需直接共享数据。"
      },
      "examples": [
        {
          "en": "Federated learning is used to train models on mobile devices while preserving user privacy.",
          "zh": "联邦学习用于在移动设备上训练模型，同时保护用户隐私。"
        },
        {
          "en": "In healthcare, federated learning allows hospitals to improve diagnostics without compromising patient data confidentiality.",
          "zh": "在医疗保健中，联邦学习允许医院在不损害患者数据机密性的情况下改进诊断。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "stochastic",
      "phonetic": "/stoʊˈkæstɪk/",
      "partOfSpeech": "adjective",
      "translation": "随机的",
      "definition": {
        "en": "Pertaining to a process involving a random variable or variables.",
        "zh": "涉及随机变量或变量的过程。"
      },
      "examples": [
        {
          "en": "Stochastic gradient descent uses a random selection of training data for each iteration.",
          "zh": "随机梯度下降在每次迭代中使用随机选择的训练数据。"
        },
        {
          "en": "Stochastic processes are fundamental in modeling uncertainties in AI systems.",
          "zh": "随机过程是模拟AI系统中不确定性的基础。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "Markov chain",
      "phonetic": "/ˈmɑːrkɒf tʃeɪn/",
      "partOfSpeech": "noun",
      "translation": "马尔可夫链",
      "definition": {
        "en": "A mathematical system that undergoes transitions from one state to another according to certain probabilistic rules.",
        "zh": "根据某些概率规则从一个状态过渡到另一个状态的数学系统。"
      },
      "examples": [
        {
          "en": "Markov chains are used in modeling dynamic systems where the next state depends only on the current state.",
          "zh": "马尔可夫链用于建模动态系统，其中下一个状态仅依赖于当前状态。"
        },
        {
          "en": "In natural language processing, Markov chains can help with text generation.",
          "zh": "在自然语言处理中，马尔可夫链可以帮助生成文本。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "one-hot encoding",
      "phonetic": "/wʌn ˈhɑt ɪnˌkəʊdɪŋ/",
      "partOfSpeech": "noun",
      "translation": "独热编码",
      "definition": {
        "en": "A process by which categorical variables are converted into a form that could be provided to machine learning algorithms to do a better job in prediction.",
        "zh": "一种将类别变量转换成机器学习算法可以更好地进行预测的形式的过程。"
      },
      "examples": [
        {
          "en": "One-hot encoding is used to represent categorical data in neural networks.",
          "zh": "独热编码用于在神经网络中表示类别数据。"
        },
        {
          "en": "It increases the dimensionality of the dataset but ensures each category is treated equally.",
          "zh": "它增加了数据集的维度，但确保每个类别都被平等对待。"
        }
      ],
      "difficulty": "basic"
    },
    {
      "word": "precision-recall curve",
      "phonetic": "/prɪˈsɪʒən rɪˈkɔːl kɜːv/",
      "partOfSpeech": "noun",
      "translation": "精确率-召回率曲线",
      "definition": {
        "en": "A graph that plots the trade-off between precision and recall for different thresholds in a classifier.",
        "zh": "一个图表，展示了在分类器中不同阈值下的精确率和召回率之间的权衡。"
      },
      "examples": [
        {
          "en": "The precision-recall curve helps in choosing the optimal threshold for classification.",
          "zh": "精确率-召回率曲线有助于选择分类的最佳阈值。"
        },
        {
          "en": "When dealing with imbalanced datasets, the precision-recall curve is often more informative than ROC curves.",
          "zh": "在处理不平衡数据集时，精确率-召回率曲线通常比ROC曲线更具信息性。"
        }
      ],
      "difficulty": "advanced"
    },
    {
      "word": "bagging",
      "phonetic": "/ˈbæɡɪŋ/",
      "partOfSpeech": "noun",
      "translation": "装袋",
      "definition": {
        "en": "A machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression.",
        "zh": "一种机器学习集成元算法，旨在提高用于统计分类和回归的机器学习算法的稳定性和准确性。"
      },
      "examples": [
        {
          "en": "Bagging reduces variance and helps to avoid overfitting.",
          "zh": "装袋减少了方差，有助于避免过拟合。"
        },
        {
          "en": "Random Forests are an example of bagging applied to decision trees.",
          "zh": "随机森林是装袋应用于决策树的一个例子。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "autoregressive model",
      "phonetic": "/ˌɔː.təʊ.rɪˈɡrɛsɪv ˈmɒdəl/",
      "partOfSpeech": "noun",
      "translation": "自回归模型",
      "definition": {
        "en": "A type of stochastic model where the output variable depends linearly on its own previous values.",
        "zh": "一种随机模型，其输出变量线性依赖于其自身的先前值。"
      },
      "examples": [
        {
          "en": "Time series analysis often uses autoregressive models to predict future values based on past data.",
          "zh": "时间序列分析通常使用自回归模型基于过去的数据来预测未来值。"
        },
        {
          "en": "The autoregressive model helped in smoothing the signal for clearer trend identification.",
          "zh": "自回归模型有助于平滑信号，以便更清晰地识别趋势。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "confusion matrix",
      "phonetic": "/kənˈfjuːʒən ˈmeɪtrɪks/",
      "partOfSpeech": "noun",
      "translation": "混淆矩阵",
      "definition": {
        "en": "A table used to describe the performance of a classification model by comparing actual and predicted classifications.",
        "zh": "一个表格，用于通过比较实际分类和预测分类来描述分类模型的性能。"
      },
      "examples": [
        {
          "en": "The confusion matrix showed a high rate of false positives.",
          "zh": "混淆矩阵显示了高比例的假阳性。"
        },
        {
          "en": "He analyzed the confusion matrix to adjust the model's thresholds.",
          "zh": "他分析了混淆矩阵以调整模型的阈值。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "k-fold cross-validation",
      "phonetic": "/keɪ fəʊld ˌkrɒsˌvælɪˈdeɪʃən/",
      "partOfSpeech": "noun",
      "translation": "K折交叉验证",
      "definition": {
        "en": "A resampling method that uses different portions of the data to train and test a model on each iteration to assess its ability to generalize.",
        "zh": "一种重采样方法，每次迭代中使用数据的不同部分来训练和测试模型，以评估其泛化能力。"
      },
      "examples": [
        {
          "en": "They used 10-fold cross-validation to ensure model robustness.",
          "zh": "他们使用10折交叉验证来确保模型的鲁棒性。"
        },
        {
          "en": "The performance was validated through k-fold cross-validation.",
          "zh": "性能通过k折交叉验证得到验证。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "undersampling",
      "phonetic": "/ˈʌndərˌsæm.plɪŋ/",
      "partOfSpeech": "noun",
      "translation": "欠采样",
      "definition": {
        "en": "The process of reducing the number of samples from the majority class in a dataset to balance class distribution.",
        "zh": "在数据集中减少多数类样本的数量，以平衡类别分布的过程。"
      },
      "examples": [
        {
          "en": "Undersampling was applied to deal with the imbalanced dataset.",
          "zh": "应用欠采样来处理不平衡的数据集。"
        },
        {
          "en": "They performed undersampling to reduce the majority class's dominance.",
          "zh": "他们进行了欠采样以减少多数类的优势。"
        }
      ],
      "difficulty": "intermediate"
    },
    {
      "word": "embedding",
      "phonetic": "/ɪmˈbɛdɪŋ/",
      "partOfSpeech": "noun",
      "translation": "嵌入",
      "definition": {
        "en": "A mapping of a discrete categorical variable to a vector of continuous numbers, used for representing words or entities.",
        "zh": "将离散类别变量映射到连续数字向量，用于表示词或实体。"
      },
      "examples": [
        {
          "en": "Word embeddings are used to convert words into vectors for NLP tasks.",
          "zh": "词嵌入用于将单词转换为向量以进行自然语言处理任务。"
        },
        {
          "en": "The embedding layer learns to map input tokens to dense vectors.",
          "zh": "嵌入层学习将输入标记映射到密集向量。"
        }
      ],
      "difficulty": "intermediate"
    }
  ]
}